{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw2-altunbas-begum.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khfvm2ZTbxaF"
      },
      "source": [
        "# CS412 - Machine Learning - 2020\n",
        "\n",
        "# Homework 2\n",
        "\n",
        "100 pts\n",
        "\n",
        "# Goal\n",
        "\n",
        "The goal of this homework is to get familiar feature handling and cross validation.\n",
        "\n",
        "\n",
        "# Dataset\n",
        "\n",
        "German Credit Risk dataset, prepared by Prof. Hoffman, classifies each person as having a good or bad credit risk. The dataset that we use consists of both numerical and categorical features.\n",
        "\n",
        "\n",
        "\n",
        "# Task\n",
        "\n",
        "Build a k-NN classifier with scikit-learn library to classify people as bad or good risks for the german credit dataset. \n",
        "\n",
        "# Software\n",
        "\n",
        "Documentation for the necessary functions can be accessed from the link below.\n",
        "\n",
        "[http://scikit-learn.org/stable/supervised_learning.html](http://scikit-learn.org/stable/supervised_learning.html)\n",
        "\n",
        "# Submission\n",
        "\n",
        "Follow the instructions at the end.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9WhAm9Ii-SH"
      },
      "source": [
        "# 1) Initialize\n",
        "\n",
        "First, make a copy of this notebook in your drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V99blGJZ02tQ",
        "outputId": "49513d63-a530-4595-c75b-2f178a3dcd25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Mount to your drive, in this way you can reach files that are in your drive\n",
        "# Run this cell\n",
        "# Go through the link that will be showed below\n",
        "# Select your google drive account and copy authorization code and paste here in output and press enter\n",
        "# You can also follow the steps from that link\n",
        "# https://medium.com/ml-book/simplest-way-to-open-files-from-google-drive-in-google-colab-fae14810674 \n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLcZp_XKjp2N"
      },
      "source": [
        "# 2) Load Dataset\n",
        "\n",
        "To start working for your homework, take a copy of the folder, given in the below link to your own google drive. You find the train and test data under this folder.\n",
        "\n",
        "[https://drive.google.com/drive/folders/1DbW6VxLKZv2oqFn9SwxAnVadmn1_nPXi?usp=sharing](https://drive.google.com/drive/folders/1DbW6VxLKZv2oqFn9SwxAnVadmn1_nPXi?usp=sharing)\n",
        "\n",
        "After copy the folder, copy the path of the train and test dataset to paste them in the below cell to load your data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSZvqTSTbsv8"
      },
      "source": [
        "import pandas as pd\n",
        "from os.path import join\n",
        "\n",
        "path_prefix = \"/content/drive/My Drive\"\n",
        "\n",
        "\n",
        "train_df = pd.read_csv(join(path_prefix,'german_credit_train.csv'))\n",
        "test_df = pd.read_csv(join(path_prefix,'german_credit_test.csv'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4PwZVkZkCZQ"
      },
      "source": [
        "# 3) Optional - Analyze the Dataset \n",
        "\n",
        "You can use the functions of the pandas library to analyze your train dataset in detail - **this part is OPTIONAL - look around the data as you wish**.\n",
        "\n",
        "\n",
        "*   Display the number of instances and features in the train ***(shape function can be used)**\n",
        "*   Display 5 random examples from the train ***(sample function can be used)**\n",
        "*   Display the information about each features ***(info method can be used)**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XdZUTLqkAw7",
        "outputId": "a827a9ad-4e4c-4712-ee16-ac2bba99e8ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Print shape\n",
        "print(\"Train data dimensionality: \", )\n",
        "\n",
        "print (train_df.shape)\n",
        "\n",
        "# Print random 5 rows\n",
        "print(\"Examples from train data: \")\n",
        "print (train_df.sample(5))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train data dimensionality: \n",
            "(800, 13)\n",
            "Examples from train data: \n",
            "    AccountStatus  Duration CreditHistory  ...  OtherInstallPlans Housing Risk\n",
            "585           A11        21           A32  ...               A143    A151    1\n",
            "219           A11        12           A32  ...               A143    A152    1\n",
            "216           A11        12           A32  ...               A143    A152    1\n",
            "499           A14        24           A34  ...               A143    A152    1\n",
            "782           A12        12           A34  ...               A143    A152    1\n",
            "\n",
            "[5 rows x 13 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLL4s7GFsBVJ",
        "outputId": "ad18a2cb-6e78-491a-ca2e-7e068fbfc5b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Print the information about the dataset\n",
        "print(\"Information about train data:\")\n",
        "print (train_df.info())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Information about train data:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 800 entries, 0 to 799\n",
            "Data columns (total 13 columns):\n",
            " #   Column             Non-Null Count  Dtype \n",
            "---  ------             --------------  ----- \n",
            " 0   AccountStatus      800 non-null    object\n",
            " 1   Duration           800 non-null    int64 \n",
            " 2   CreditHistory      800 non-null    object\n",
            " 3   CreditAmount       800 non-null    int64 \n",
            " 4   SavingsAccount     800 non-null    object\n",
            " 5   EmploymentSince    800 non-null    object\n",
            " 6   PercentOfIncome    800 non-null    int64 \n",
            " 7   PersonalStatus     800 non-null    object\n",
            " 8   Property           800 non-null    object\n",
            " 9   Age                800 non-null    int64 \n",
            " 10  OtherInstallPlans  800 non-null    object\n",
            " 11  Housing            720 non-null    object\n",
            " 12  Risk               800 non-null    int64 \n",
            "dtypes: int64(5), object(8)\n",
            "memory usage: 81.4+ KB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yVSSt0mtH0W"
      },
      "source": [
        "# 4) Define your train and test labels\n",
        "\n",
        "*  Define labels for both train and test data in new arrays \n",
        "*  And remove the label column from both train and test sets do tht it is not used as a feature! \n",
        "\n",
        "\n",
        "(**you can use pop method**)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heg3V6IssehF"
      },
      "source": [
        "# Define labels\n",
        "train_label = train_df['Risk']\n",
        "test_label = test_df['Risk']\n",
        "\n",
        "#Remove label column\n",
        "holding_train=train_df[\"Risk\"]\n",
        "holding_test=test_df[\"Risk\"]\n",
        "\n",
        "\n",
        "train_df=train_df.drop(columns=[\"Risk\"])\n",
        "test_df=test_df.drop(columns=[\"Risk\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGw3v-ai4jTN"
      },
      "source": [
        "# 5) Handle missing values if any \n",
        "\n",
        "*   Print the columns that have **NaN** values (**isnull** method can be used)\n",
        "*   You can impute missing values with mode of that feature or remove samples or attributes\n",
        "*   To impute the test set, you should use the mode values that you obtain from **train** set, as **you should not be looking at your test data to gain any information or advantage.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TNKte7c8EpR",
        "outputId": "83f009cf-e614-4966-f675-0b39d822f913",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Print columns with NaN values\n",
        "\n",
        "print (\"Train Set:\",)\n",
        "print (train_df.isnull().any())\n",
        "\n",
        "#train_df.isnull().sum()\n",
        "# we have 80 NaN values in housing column\n",
        "print (\"Test Set:\")\n",
        "print (test_df.isnull().any())\n",
        "print (\"Only Housing returned True so we have NaN values only in Housing column for both train and test sets\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Set:\n",
            "AccountStatus        False\n",
            "Duration             False\n",
            "CreditHistory        False\n",
            "CreditAmount         False\n",
            "SavingsAccount       False\n",
            "EmploymentSince      False\n",
            "PercentOfIncome      False\n",
            "PersonalStatus       False\n",
            "Property             False\n",
            "Age                  False\n",
            "OtherInstallPlans    False\n",
            "Housing               True\n",
            "dtype: bool\n",
            "Test Set:\n",
            "AccountStatus        False\n",
            "Duration             False\n",
            "CreditHistory        False\n",
            "CreditAmount         False\n",
            "SavingsAccount       False\n",
            "EmploymentSince      False\n",
            "PercentOfIncome      False\n",
            "PersonalStatus       False\n",
            "Property             False\n",
            "Age                  False\n",
            "OtherInstallPlans    False\n",
            "Housing               True\n",
            "dtype: bool\n",
            "Only Housing returned True so we have NaN values only in Housing column for both train and test sets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hd6s66xKLEiO"
      },
      "source": [
        "# Impute missing values by replacing with mode value\n",
        "\n",
        "train_df[\"Housing\"].value_counts()\n",
        "\n",
        "train_df[\"Housing\"].mode()[0]\n",
        "train_df[\"Housing\"]=train_df[\"Housing\"].fillna(train_df[\"Housing\"].mode()[0])\n",
        "\n",
        "\n",
        "test_df[\"Housing\"]=test_df[\"Housing\"].fillna(train_df[\"Housing\"].mode()[0])\n",
        "#check if we still have nan values\n",
        "#train_df.isnull().sum()\n",
        "#test_df.isnull().sum()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkgqFpyr2BrX"
      },
      "source": [
        "# 6) Transform categorical / ordinal features\n",
        "\n",
        "* Transform all categorical / ordinal features using the methods that you have learnt in lectures and recitation 4 for both train and test data\n",
        "* You saw the dictionary use for mapping in recitation. (You can use **replace function** to assign new values to the categories of a column).\n",
        "\n",
        "*  The class of the categorical attributes in the dataset are defined as follows:\n",
        "  - Status of existing checking account\n",
        "     - A11 :      ... <    0 DM\n",
        "\t- A12 : 0 <= ... <  200 DM\n",
        "\t- A13 :      ... >= 200 DM / salary assignments for at least 1 year\n",
        "     - A14 : no checking account\n",
        "\n",
        " - Credit history\n",
        "    - A30 : no credits taken/all credits paid back duly\n",
        "    - A31 : all credits at this bank paid back duly\n",
        "\t- A32 : existing credits paid back duly till now\n",
        "    - A33 : delay in paying off in the past\n",
        "\t- A34 : critical account/other credits existing (not at this bank)\n",
        "\n",
        "  - Savings account\n",
        "    - A61 :          ... <  100 DM\n",
        "\t- A62 :   100 <= ... <  500 DM\n",
        "\t- A63 :   500 <= ... < 1000 DM\n",
        "\t- A64 :          .. >= 1000 DM\n",
        "    - A65 :   unknown/ no savings account\n",
        "\n",
        " - Employment Since\n",
        "    - A71 : unemployed\n",
        "    - A72 :       ... < 1 year\n",
        "\t- A73 : 1  <= ... < 4 years  \n",
        "\t- A74 : 4  <= ... < 7 years\n",
        "\t- A75 :       .. >= 7 years\n",
        " \n",
        " - Personal Status\n",
        "    - A91 : male   : divorced/separated\n",
        "\t- A92 : female : divorced/separated/married\n",
        "    - A93 : male   : single\n",
        "\t- A94 : male   : married/widowed\n",
        "\t- A95 : female : single\n",
        "\n",
        "  - Property\n",
        "     -  A121 : real estate\n",
        "\t- A122 : if not A121 : building society savings agreement/life insurance\n",
        "    - A123 : if not A121/A122 : car or other, not in attribute 6\n",
        "\t- A124 : unknown / no property\n",
        "\n",
        " - OtherInstallPlans  \n",
        "    - A141 : bank\n",
        "\t- A142 : stores\n",
        "\t- A143 : none\n",
        "\n",
        " - Housing\n",
        "    -  A151 : rent\n",
        "\t - A152 : own\n",
        "\t- A153 : for free"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Evng6_DyYevs",
        "outputId": "2dd5b2d9-9693-4dbc-c42a-9d87df46611e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "# Transform the categorical / ordinal attributes\n",
        "\n",
        "account_status_transformed={'A11':0,\"A12\" : 1,\"A13\" :2, \"A14\" : 3 }\n",
        "train_df[\"AccountStatus\"] = train_df[\"AccountStatus\"].replace(account_status_transformed)\n",
        "test_df[\"AccountStatus\"] = test_df[\"AccountStatus\"].replace(account_status_transformed)\n",
        "\n",
        "\n",
        "##SOR BURAYI\n",
        "credit_history_transformed={ \"A30\" : 4,\"A31\" : 3,\"A32\" : 2,\"A33\" : 1, \"A34\" : 0}\n",
        "train_df[\"CreditHistory\"] = train_df[\"CreditHistory\"].replace(credit_history_transformed)\n",
        "test_df[\"CreditHistory\"] = test_df[\"CreditHistory\"].replace(credit_history_transformed)\n",
        "\n",
        "\n",
        "savings_account_transformed={\"A61\" : 0,\"A62\" : 1, \"A63\" : 2, \"A64\" : 3, \"A65\" : 4}\n",
        "train_df[\"SavingsAccount\"] = train_df[\"SavingsAccount\"].replace(savings_account_transformed)\n",
        "test_df[\"SavingsAccount\"] = test_df[\"SavingsAccount\"].replace(savings_account_transformed)\n",
        "\n",
        "\n",
        "emp_since_transformed={ \"A71\" : 0,\"A72\" : 1, \"A73\" : 2, \"A74\" : 3,\"A75\" : 4}\n",
        "train_df[\"EmploymentSince\"]=train_df[\"EmploymentSince\"].replace(emp_since_transformed)\n",
        "test_df[\"EmploymentSince\"]=test_df[\"EmploymentSince\"].replace(emp_since_transformed)\n",
        "\n",
        "\n",
        "pers_status_transformed={ \"A91\" : \"male : divorced/separated\",\"A92\" : \"female : divorced/separated/married\",\"A93\" : \"male : single\",\"A94\" : \"male : married/widowed\",\"A95\" : \"female : single\"}\n",
        "train_df['PersonalStatus']=train_df['PersonalStatus'].replace(pers_status_transformed)\n",
        "test_df['PersonalStatus']=test_df['PersonalStatus'].replace(pers_status_transformed)\n",
        "\n",
        "\n",
        "property_transformed={\"A121\" : 3,\"A122\" :2,\"A123\" : 1,\"A124\" : 0}\n",
        "train_df[\"Property\"]=train_df[\"Property\"].replace(property_transformed)\n",
        "test_df[\"Property\"]=test_df[\"Property\"].replace(property_transformed)\n",
        "\n",
        "\n",
        "OtherInstallPlans_transformed={\"A141\":\"bank\",\"A142\":\"stores\",\"A143\":\"none\"}\n",
        "train_df['OtherInstallPlans']=train_df['OtherInstallPlans'].replace(OtherInstallPlans_transformed)\n",
        "test_df['OtherInstallPlans']=test_df['OtherInstallPlans'].replace(OtherInstallPlans_transformed)\n",
        "\n",
        "\n",
        "Housing_transformed={\"A151\":\"rent\", \"A152\":\"own\",\"A153\":\"for free\"}\n",
        "train_df['Housing']=train_df['Housing'].replace(Housing_transformed)\n",
        "test_df['Housing']=test_df['Housing'].replace(Housing_transformed)\n",
        "\n",
        "\n",
        "train_df.head()\n",
        "#test_df.head()                                                       \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AccountStatus</th>\n",
              "      <th>Duration</th>\n",
              "      <th>CreditHistory</th>\n",
              "      <th>CreditAmount</th>\n",
              "      <th>SavingsAccount</th>\n",
              "      <th>EmploymentSince</th>\n",
              "      <th>PercentOfIncome</th>\n",
              "      <th>PersonalStatus</th>\n",
              "      <th>Property</th>\n",
              "      <th>Age</th>\n",
              "      <th>OtherInstallPlans</th>\n",
              "      <th>Housing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>2859</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>male : single</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>none</td>\n",
              "      <td>own</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>2136</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>male : single</td>\n",
              "      <td>3</td>\n",
              "      <td>25</td>\n",
              "      <td>none</td>\n",
              "      <td>own</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>5302</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>male : single</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>none</td>\n",
              "      <td>for free</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>2</td>\n",
              "      <td>8978</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>male : divorced/separated</td>\n",
              "      <td>2</td>\n",
              "      <td>45</td>\n",
              "      <td>none</td>\n",
              "      <td>own</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>15</td>\n",
              "      <td>2</td>\n",
              "      <td>4623</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>male : single</td>\n",
              "      <td>2</td>\n",
              "      <td>40</td>\n",
              "      <td>none</td>\n",
              "      <td>own</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   AccountStatus  Duration  CreditHistory  ...  Age  OtherInstallPlans   Housing\n",
              "0              3        12              2  ...   38               none       own\n",
              "1              0         9              2  ...   25               none       own\n",
              "2              0        18              0  ...   36               none  for free\n",
              "3              0        14              2  ...   45               none       own\n",
              "4              3        15              2  ...   40               none       own\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rU6xC1VAOf--"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "enc1 = OneHotEncoder(handle_unknown='ignore')\n",
        "dummies_personal = enc1.fit_transform(train_df[['PersonalStatus']]).toarray()\n",
        "dummies_personal = pd.DataFrame(dummies_personal,columns=enc1.categories_)\n",
        "\n",
        "\n",
        "######\n",
        "\n",
        "enc2=OneHotEncoder(handle_unknown=\"ignore\")\n",
        "dummies_housing=enc2.fit_transform(train_df[['Housing']]).toarray()\n",
        "dummies_housing=pd.DataFrame(dummies_housing,columns=enc2.categories_)\n",
        "\n",
        "\n",
        "#######\n",
        "\n",
        "enc3=OneHotEncoder(handle_unknown=\"ignore\")\n",
        "dummies_plans=enc3.fit_transform(train_df[['OtherInstallPlans']]).toarray()\n",
        "dummies_plans=pd.DataFrame(dummies_plans,columns=enc3.categories_)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "###TEST SET KISMI####\n",
        "\n",
        "\n",
        "\n",
        "dummies_personal_test = enc1.transform(test_df[['PersonalStatus']]).toarray()\n",
        "dummies_personal_test = pd.DataFrame(dummies_personal_test,columns=enc1.categories_)\n",
        "\n",
        "\n",
        "\n",
        "dummies_housing_test = enc2.transform(test_df[['Housing']]).toarray()\n",
        "dummies_housing_test = pd.DataFrame(dummies_housing_test,columns=enc2.categories_)\n",
        "\n",
        "\n",
        "\n",
        "dummies_plans_test = enc3.transform(test_df[['OtherInstallPlans']]).toarray()\n",
        "dummies_plans_test = pd.DataFrame(dummies_plans_test,columns=enc3.categories_)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5nEDD-1A3j-"
      },
      "source": [
        "##MERGE DATASETS WITH NDUMMY VARIABLES AND DROP ORIG COLUMNS\n",
        "\n",
        "train_df=pd.merge(train_df,dummies_housing,right_index=True,left_index=True)\n",
        "train_df=train_df.drop(columns=\"Housing\")\n",
        "\n",
        "\n",
        "\n",
        "train_df=pd.merge(train_df,dummies_personal,right_index=True,left_index=True)\n",
        "train_df=train_df.drop(columns=\"PersonalStatus\")\n",
        "\n",
        "\n",
        "\n",
        "train_df=pd.merge(train_df,dummies_plans,right_index=True,left_index=True)\n",
        "train_df=train_df.drop(columns=\"OtherInstallPlans\")\n",
        "\n",
        "\n",
        "\n",
        "test_df=pd.merge(test_df,dummies_housing_test,right_index=True,left_index=True)\n",
        "test_df=test_df.drop(columns=\"Housing\")\n",
        "\n",
        "\n",
        "\n",
        "test_df=pd.merge(test_df,dummies_personal_test,right_index=True,left_index=True)\n",
        "test_df=test_df.drop(columns=\"PersonalStatus\")\n",
        "\n",
        "\n",
        "test_df=pd.merge(test_df,dummies_plans_test,right_index=True,left_index=True)\n",
        "test_df=test_df.drop(columns=\"OtherInstallPlans\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVcTCh9-AnFv"
      },
      "source": [
        "# 7) Build a k-NN classifier on training data and perform models selection using 5 fold cross validation\n",
        "\n",
        "*  Initialize k-NN classifiers with **k= 5, 10, 15**\n",
        "*  Calculate the cross validation scores using cross_al_score method, number of folds is 5. \n",
        "*  Note: Xval is performed on training data! Do not use test data in any way and do not separate a hold-out validation set, rather use cross-validation.\n",
        "\n",
        "Documentation of the cross_val_score method:\n",
        "\n",
        "[https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score)\n",
        "\n",
        "*  Stores the average accuracies of these folds\n",
        "*  Select the value of k using the cross validation results. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ficAs0W52b8r",
        "outputId": "d02ec292-2a80-4782-b07a-ece6faa7f2ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from statistics import mean\n",
        "\n",
        "# k values\n",
        "kVals = [5,10,15]\n",
        "\n",
        "# Save the accuracies of each value of kVal in [accuracies] variable\n",
        "accuracies = []\n",
        "\n",
        "# Loop over values of k for the k-Nearest Neighbor classifier\n",
        "for k in kVals:\n",
        "  # Initialize a k-NN classifier with k neighbors\n",
        "  knn = KNeighborsClassifier(n_neighbors=k)\n",
        "  # Calculate the 5 fold cross validation scores using cross_val_score\n",
        "  # cv parameter: number of folds, in our case it must be 5\n",
        "  scores = cross_val_score(knn,train_df,train_label,cv=5)\n",
        "  accuracies.append(scores.mean())\n",
        "  # Stores the average accuracies of the scores in accuracies variable, you can use mean method\n",
        "\n",
        "\n",
        "print(accuracies)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.68, 0.7074999999999999, 0.7100000000000001]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_t4ss1Ixglor"
      },
      "source": [
        "# 8) Retrain using all training data and test on test set\n",
        "\n",
        "* Train a classifier with the chosen k value of the best classifier using **all training data**. \n",
        "\n",
        "Note:  k-NN training involves no explicit training, but this is what we would do after model selection with decision trees or any other ML approach (we had 5 diff. models -one for each fold - for each k in the previous step - dont know which one to submit. Even if we picked the best one, it does not use all training samples.\n",
        "\n",
        "* Predict the labels of testing data \n",
        "\n",
        "* Report the accuracy "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qi3pfvaBKTcg",
        "outputId": "a25bd561-4de9-40eb-c0df-7e6fe6e47148",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "# Train the best classifier using all training set\n",
        "\n",
        "best_knn=  KNeighborsClassifier(kVals[np.argmax(accuracies)])\n",
        "best_knn.fit (train_df,train_label)\n",
        "\n",
        "\n",
        "\n",
        "# Estimate the prediction of the test data\n",
        "prediction= best_knn.predict(test_df)\n",
        "\n",
        "# Print accuracy of test data\n",
        "accuracy_sc= accuracy_score(prediction,test_label)\n",
        "print (\"The accuracy score is: \",accuracy_sc)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy score is:  0.665\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4ZCEjEXiMGi"
      },
      "source": [
        "# 9) Bonus (5pts)\n",
        "\n",
        "There is a limited bonus for any extra work that you may use and improve the above results. \n",
        "\n",
        "You may try a larger k values, scale input features, remove some features, .... Please **do not overdo**, maybe spend another 30-60min on this. The idea is not do an exhaustive search (which wont help your understanding of ML process), but just to give some extra points to those who may look at the problem a little more comprehensively. \n",
        "\n",
        "**If you obtain better results than the above, please indicate the best model you have found and the corresponding accuracy.**\n",
        "\n",
        "E.g. using feature normalization ..... and removing .... features and using a value k=...., I have obtained ....% accuracy.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5AuzuKliQiY"
      },
      "source": [
        "# 10) Notebook & Report\n",
        "\n",
        "**Notebook:** We may just look at your notebook results; so make sure each cell is run and outputs are there.\n",
        "\n",
        "**Report:** Write an at most 1/2 page summary of your approach to this problem at the end of your notebook; this should be like an abstract of a paper or the executive summary.\n",
        "\n",
        "**Must include statements such as:**\n",
        "\n",
        "( Include the problem definition: 1-2 lines )\n",
        "\n",
        "(Talk about any preprocessing you do, How you handle missing values and categorical features)\n",
        "\n",
        "( Give the average validation accuracies for different k values and standard deviations between 5 folds of each k values, state which one you selected)\n",
        "\n",
        "( State what your test results are with the chosen method, parameters: e.g. \"We have obtained the best results with the ….. classifier (parameters=....) , giving classification accuracy of …% on test data….\"\"\n",
        "\n",
        "State if there is any **bonus** work...\n",
        "\n",
        "You will get full points from here as long as you have a good (enough) summary of your work, regardless of your best performance or what you have decided to talk about in the last few lines."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtGLTL88sS1Y"
      },
      "source": [
        "# <font color=\"coral\"> **REPORT** </font>\n",
        "<font color= \"turquoise\">We are given a credit applicability problem to use with KNN classifier algorithm. First I labelled my target attribute which is \"Risk\" column. Later on I found the column with NaN values, which was \"Housing\", then I filled NaN values with using mode function. After that I categorized Columns according to ordinal or categorical features. Which I choose **categorical** only for \"**Personal Status**\", \"**Other Install Plans**\" and \"**Housing**\". After choosing them as categorical I used \"**One hot Encoder**\" to turn them into numeric values. For final part before choosing the best K valued model, I did Cross Validation using 5 folds. And decided on the best k-value according to my accuracy scores that I got from cv. Finally I used k=15 and got accuracy score of **0.665**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaPs6f7mkiI0"
      },
      "source": [
        "# 11) Submission\n",
        "\n",
        "Please submit your **\"share link\" INLINE in Sucourse submissions**. That is we should be able to click on the link and go there and run (and possibly also modify) your code. \n",
        "\n",
        "For us to be able to modify, in case of errors etc, **you should get your \"share link\" as **share with anyone in edit mode** \n",
        "\n",
        " **Also submit your notebook as pdf as attachment**, choose print and save as PDF, save with hw2-lastname-firstname.pdf to facilitate grading. \n"
      ]
    }
  ]
}